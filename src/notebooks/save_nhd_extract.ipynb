{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8e9b643",
   "metadata": {},
   "source": [
    "# Save a file for each HUC with reach geoms and ids\n",
    "\n",
    "To make things more cloud-friendly, we want to save a portion of the NHD database in a set of GeoJSON files which can be stored on S3. Each file will have the reach geometries and associated ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "45c95b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import psycopg2\n",
    "import shapely\n",
    "import shapely.wkt\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "import numpy as np\n",
    "import pyproj\n",
    "import dask.bag as db\n",
    "from dask.distributed import Client\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "320dbbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cursor(database):\n",
    "    connection = psycopg2.connect(host=\"database\", database=database,user=\"postgres\", password=\"password\")\n",
    "    cursor = connection.cursor()\n",
    "    return cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e3138",
   "metadata": {},
   "source": [
    "# Get all HUC12s and write a GeoJSON file for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7606e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_huc12s(database):\n",
    "    cursor = get_cursor(database)\n",
    "    query = \"select huc12 from wbdhu12\"\n",
    "    cursor.execute(query)\n",
    "    return [c[0] for c in cursor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15962746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_huc12_extract(huc12, out_dir):\n",
    "    # get huc12 boundary\n",
    "    cursor = get_cursor('nhdplushr')\n",
    "    query = \"SELECT wkb_geometry from wbdhu12 WHERE huc12=%s\"\n",
    "    cursor.execute(query, [huc12])\n",
    "    huc_geom = shapely.wkb.loads(cursor.fetchone()[0].tobytes())\n",
    "    \n",
    "    # get reaches intersecting with huc boundary\n",
    "    cursor = get_cursor('nhdplusv2')\n",
    "    query = f'''\n",
    "        SELECT comid, ST_Force2D(wkb_geometry) from nhdflowline WHERE ST_Intersects(\n",
    "            ST_GeomFromWKB(wkb_geometry, 4326), ST_GeomFromGeoJSON(%s))\n",
    "        '''\n",
    "    huc_geom_str = json.dumps(shapely.geometry.mapping(huc_geom))\n",
    "    cursor.execute(query, [huc_geom_str])\n",
    "    reach_geoms = []\n",
    "    reach_ids = []\n",
    "    for reach_id, reach_geom in cursor:\n",
    "        reach_ids.append(int(reach_id))\n",
    "        reach_geoms.append(shapely.wkb.loads(reach_geom, hex=True))\n",
    "\n",
    "    # make dataframe with comid and geometries and save to GeoJSON    \n",
    "    df = gpd.GeoDataFrame({'comid': reach_ids + [0], 'geometry': reach_geoms + [huc_geom]})\n",
    "    out_path = os.path.join(out_dir, f'{huc12}.json')\n",
    "    df.to_file(out_path, driver='GeoJSON', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2506429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_huc8s(database):\n",
    "    cursor = get_cursor(database)\n",
    "    query = \"select huc8 from wbdhu8\"\n",
    "    cursor.execute(query)\n",
    "    return [c[0] for c in cursor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b69f0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_huc8_extract(huc8, out_dir):\n",
    "    # get huc8 boundary\n",
    "    cursor = get_cursor('nhdplushr')\n",
    "    query = \"SELECT wkb_geometry from wbdhu8 WHERE huc8=%s\"\n",
    "    cursor.execute(query, [huc8])\n",
    "    ## huc_geom = shapely.wkb.loads(cursor.fetchone()[0].tobytes())\n",
    "    huc_geom = shapely.wkb.loads(cursor.fetchone()[0], hex=True)\n",
    "\n",
    "    # get reaches intersecting with huc boundary\n",
    "    cursor = get_cursor('nhdplusv2')\n",
    "    query = f'''\n",
    "        SELECT comid, ST_Force2D(wkb_geometry) from nhdflowline WHERE ST_Intersects(\n",
    "            ST_GeomFromWKB(wkb_geometry, 4326), ST_GeomFromGeoJSON(%s))\n",
    "        '''\n",
    "    huc_geom_str = json.dumps(shapely.geometry.mapping(huc_geom))\n",
    "    cursor.execute(query, [huc_geom_str])\n",
    "    reach_geoms = []\n",
    "    reach_ids = []\n",
    "    for reach_id, reach_geom in cursor:\n",
    "        reach_ids.append(int(reach_id))\n",
    "        reach_geoms.append(shapely.wkb.loads(reach_geom, hex=True))\n",
    "\n",
    "    # make dataframe with comid and geometries and save to GeoJSON\n",
    "    df = gpd.GeoDataFrame({'comid': reach_ids + [0], 'geometry': reach_geoms + [huc_geom]})\n",
    "    out_path = os.path.join(out_dir, f'{huc8}.json')\n",
    "    df.to_file(out_path, driver='GeoJSON', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d95c104c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.9/site-packages/distributed/node.py:160: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 34689 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    limit = npartitions = 10\n",
    "    client = Client()\n",
    "\n",
    "    ## HUC12\n",
    "    huc12s = get_huc12s(\"nhdplushr\")\n",
    "    huc12_out_dir = f'/opt/data/noaa/huc12-extracts/'\n",
    "    os.makedirs(huc12_out_dir, exist_ok=True)\n",
    "    if len(os.listdir(huc12_out_dir)) < len(huc12s)):\n",
    "        ## Only run if there appear to be missing files\n",
    "        huc12_bag = db.from_sequence(huc12s, npartitions=npartitions)\n",
    "        out12 = huc12_bag.map(save_huc12_extract, huc12_out_dir).compute()\n",
    "    else:\n",
    "        print(f\"Thi\")\n",
    "\n",
    "    ## HUC8\n",
    "    huc8s = get_huc8s(\"nhdplushr\")\n",
    "    huc8_out_dir = f'/opt/data/noaa/huc8-extracts/'\n",
    "    os.makedirs(huc8_out_dir, exist_ok=True)\n",
    "    if len(os.listdir(huc8_out_dir)) < len(huc8s)):\n",
    "        huc8_bag = db.from_sequence(huc8s, npartitions=npartitions)\n",
    "        out8 = huc8_bag.map(save_huc8_extract, huc8_out_dir).compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008f837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
