# inspired by https://raw.githubusercontent.com/pipekit/talk-demos/main/argocon-demos/2021-processing-petabytes-with-dask/dask_standard_cluster_workflow_template.yaml
apiVersion: argoproj.io/v1alpha1
#kind: ClusterWorkflowTemplate
kind: Workflow
metadata:
  generateName: dask-distributed-task-workflow-
spec:
  entrypoint: execute-dask-job
  securityContext:
    fsGroup: 1000
  volumeClaimTemplates:
    - metadata:
        name: scratch
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 128Gi
  arguments:
    parameters:
      - name: script-location
      - name: image
        value: "pangeo/pangeo-notebook:2022.05.18"
      - name: n-workers
        value: "1"
      - name: worker-cores
        value: "1"
      - name: worker-mem-gb
        value: "2"
      - name: scheduler-cores
        value: "1"
      - name: scheduler-mem-gb
        value: "4"
  templates:
    - name: execute-dask-job
      inputs:
        parameters:
          - name: script-location
          - name: image
          - name: n-workers
          - name: worker-cores
          - name: worker-mem-gb
          - name: scheduler-cores
          - name: scheduler-mem-gb
      script:
        image: "{{inputs.parameters.image}}"
        imagePullPolicy: Always
        command: [bash]
        env:
          - name: DASK_GATEWAY__ADDRESS
            value: http://traefik-dask-gateway/services/dask-gateway
          - name: DASK_GATEWAY__PROXY_ADDRESS
            value: gateway://traefik-dask-gateway:80
          - name: DASK_GATEWAY__PUBLIC_ADDRESS
            value: /services/dask-gateway
          - name: DASK_GATEWAY__AUTH_TYPE
            value: jupyterhub
          - name: JUPYTERHUB_API_TOKEN
            valueFrom:
              secretKeyRef:
                name: auth-token
                key: token
          - name: DASK_OPTS__WORKER_MEMORY
            value: "{{inputs.parameters.worker-mem-gb}}"
          - name: DASK_OPTS__WORKER_CORES
            value: "{{inputs.parameters.worker-cores}}"
          - name: DASK_OPTS__N_WORKERS
            value: "{{inputs.parameters.n-workers}}"
          - name: DASK_OPTS__SCHEDULER_MEMORY
            value: "{{inputs.parameters.scheduler-mem-gb}}"
          - name: DASK_OPTS__SCHEDULER_CORES
            value: "{{inputs.parameters.scheduler-cores}}"
        volumeMounts:
          - name: scratch
            mountPath: /scratch
        workingDir: "/scratch"
        source: |
          pwd
          export
          wget -q --output-document=source.py "{{inputs.parameters.script-location}}"
          python source.py
